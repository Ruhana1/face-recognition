{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 224\n",
    "img_cols = 224 \n",
    "\n",
    "base_model = VGG16(weights = 'imagenet', \n",
    "                 include_top = False, \n",
    "                 input_shape = (img_rows, img_cols, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.layers[0].__class__.__name__\n",
    "base_model.layers[0].input\n",
    "\n",
    "#Freezing all the layers by making their trainable=False\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "#Checking this\n",
    "base_model.layers[12].trainable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 Conv2D False\n",
      "2 Conv2D False\n",
      "3 MaxPooling2D False\n",
      "4 Conv2D False\n",
      "5 Conv2D False\n",
      "6 MaxPooling2D False\n",
      "7 Conv2D False\n",
      "8 Conv2D False\n",
      "9 Conv2D False\n",
      "10 MaxPooling2D False\n",
      "11 Conv2D False\n",
      "12 Conv2D False\n",
      "13 Conv2D False\n",
      "14 MaxPooling2D False\n",
      "15 Conv2D False\n",
      "16 Conv2D False\n",
      "17 Conv2D False\n",
      "18 MaxPooling2D False\n"
     ]
    }
   ],
   "source": [
    "for (i,layer) in enumerate(base_model.layers):\n",
    "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "top_model = base_model.output\n",
    "top_model = Flatten()(top_model)\n",
    "top_model = Dense(512, activation='relu')(top_model)   #First added FCL dense layer\n",
    "top_model = Dense(512, activation='relu')(top_model)    #Second added FCL dense layer\n",
    "top_model = Dense(256, activation='relu')(top_model)    #Third added FCL dense layer\n",
    "top_model = Dense(4, activation='softmax')(top_model)    #Output layer with 2 class labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "newmodel = Model(inputs=base_model.input, outputs=top_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 266 images belonging to 4 classes.\n",
      "Found 33 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data=\"ruhi/train/\"\n",
    "validation_data=\"ruhi/test/\"\n",
    "#Data image augmentation\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        class_mode='categorical')\n",
    " \n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        validation_data,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "newmodel.compile(optimizer = 'adam',\n",
    "                 loss = 'categorical_crossentropy',\n",
    "                 metrics =['accuracy']\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 [==============================] - 529s 11s/step - loss: 1.5548 - accuracy: 0.4262 - val_loss: 1.8365 - val_accuracy: 0.4848\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.83651, saving model to VGG16.h5\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 521s 10s/step - loss: 0.7530 - accuracy: 0.6669 - val_loss: 0.1779 - val_accuracy: 0.6970\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.83651 to 0.17789, saving model to VGG16.h5\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 517s 10s/step - loss: 0.5186 - accuracy: 0.8038 - val_loss: 0.3192 - val_accuracy: 0.6970\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17789\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 534s 11s/step - loss: 0.4781 - accuracy: 0.8094 - val_loss: 1.4270 - val_accuracy: 0.7273\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.17789\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 530s 11s/step - loss: 0.4276 - accuracy: 0.8228 - val_loss: 1.0046 - val_accuracy: 0.6364\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.17789\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "                     \n",
    "checkpoint = ModelCheckpoint(\"VGG16.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, checkpoint]\n",
    "\n",
    "# We use a very small learning rate \n",
    "newmodel.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = Adam(lr = 0.001),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Enter the number of training and validation samples here\n",
    "nb_train_samples = 266\n",
    "nb_validation_samples = 33\n",
    "\n",
    "# We only train 5 EPOCHS \n",
    "epochs = 5\n",
    "batch_size = 16\n",
    "\n",
    "history = newmodel.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 50 ,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = test_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel.save('virat.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "classifier = load_model('virat.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class - rohit\n",
      "Class - rohit\n",
      "Class - virat\n",
      "Class - dhoni\n",
      "Class - dhoni\n",
      "Class - dhoni\n",
      "Class - rohit\n",
      "Class - dhoni\n",
      "Class - dhoni\n",
      "Class - hardik\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "five_celeb_dict = {\"[0]\": \"dhoni\", \n",
    "                   \"[1]\": \"hardik\",\n",
    "                   \"[2]\": \"rohit\",\n",
    "                   \"[3]\": \"virat\"}\n",
    "\n",
    "five_celeb_dict_n = {\"dhoni\": \"dhoni\", \n",
    "                     \"hardik\": \"hardik\",\n",
    "                     \"rohit\": \"rohit\",\n",
    "                     \"virat\": \"virat\"}\n",
    "\n",
    "def draw_test(name, pred, im):\n",
    "    celeb =five_celeb_dict[str(pred)]\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 80, 0, 0, 100 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, celeb, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "def getRandomImage(path):\n",
    "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    print(\"Class - \" + five_celeb_dict_n[str(path_class)])\n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    return cv2.imread(file_path+\"/\"+image_name)    \n",
    "\n",
    "for i in range(0,10):\n",
    "    input_im = getRandomImage(\"ruhi/test/\")\n",
    "    input_original = input_im.copy()\n",
    "    input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "    input_im = input_im / 255.\n",
    "    input_im = input_im.reshape(1,224,224,3) \n",
    "    \n",
    "    # Get Prediction\n",
    "    res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
    "    \n",
    "    # Show image with predicted class\n",
    "    draw_test(\"Prediction\", res, input_original) \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
